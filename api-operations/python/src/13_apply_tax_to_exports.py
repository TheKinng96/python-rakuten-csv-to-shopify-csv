#!/usr/bin/env python3
"""
Apply tax data to Shopify product export CSVs

This script reads tax information from Japanese master files and applies it to
Shopify product export CSVs by matching Handle = ÂïÜÂìÅ„Ç≥„Éº„Éâ.

Usage:
    python 13_apply_tax_to_exports.py                    # Process all export files
    python 13_apply_tax_to_exports.py --dry-run          # Preview changes without modifying files
    python 13_apply_tax_to_exports.py --backup           # Create backup files before modification
    python 13_apply_tax_to_exports.py --file products_export_1.csv  # Process single file

Requirements:
    - „Çª„ÉÉ„ÉàÂïÜÂìÅ„Éû„Çπ„Çø_20250912.csv (SHIFT-JIS encoding)
    - ÂïÜÂìÅ„Éû„Çπ„Çø_20250912.csv (SHIFT-JIS encoding)
    - products_export_*.csv files (UTF-8 encoding)
"""

import csv
import json
import shutil
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict

class TaxDataApplicator:
    def __init__(self, data_dir='/Users/gen/corekara/rakuten-shopify/api-operations/data', backup=False, dry_run=False):
        self.data_dir = Path(data_dir)
        self.backup = backup
        self.dry_run = dry_run
        self.tax_data = {}
        self.set_code_mapping = {}  # Maps „Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ to tax rate
        self.results = {
            'files_processed': 0,
            'products_updated': 0,
            'products_matched': 0,
            'products_unmatched': 0,
            'errors': []
        }
        self.unmatched_products = []
        self.matched_products = []  # Track matched products for JSON export
        
        # Japanese tax classification keywords
        # 8% tax (reduced rate) - food, beverages, essential items
        self.tax_8_keywords = [
            # Food and beverages
            'È£üÂìÅ', 'È£üÊùê', 'Á±≥', 'ËÇâ', 'È≠ö', 'ÈáéËèú', 'ÊûúÁâ©', '„Éë„É≥', '„ÅäËèìÂ≠ê', '„Çπ„Ç§„Éº„ÉÑ', 'ÂíåËèìÂ≠ê',
            'Ëå∂', '„Ç≥„Éº„Éí„Éº', 'È£≤Êñô', '„Ç∏„É•„Éº„Çπ', 'Ê∞¥', '„Éü„Éç„É©„É´„Ç¶„Ç©„Éº„Çø„Éº',
            '„Ç´„É¨„Éº', '„É©„Éº„É°„É≥', '„ÅÜ„Å©„Çì', '„Åù„Å∞', 'Âë≥Âôå', 'ÈÜ§Ê≤π', 'Ë™øÂë≥Êñô', '„ÇΩ„Éº„Çπ', '„Éâ„É¨„ÉÉ„Ç∑„É≥„Ç∞',
            '„Ç™„Ç§„É´', 'Ê≤π', 'Â°©', 'Á†ÇÁ≥ñ', 'ËúÇËúú', '„ÅØ„Å°„Åø„Å§', 'ÈÖ¢', '„Åø„Çä„Çì', 'ÊñôÁêÜ', 'ÂºÅÂΩì', 'ÊÉ£Ëèú',
            # Specific food items
            '„Ç´„É´„Éî„Çπ', '„Éê„Çø„Éº', '„ÉÅ„Éº„Ç∫', '„É®„Éº„Ç∞„É´„Éà', 'Áâõ‰π≥', '„Éü„É´„ÇØ', 'Âçµ', '„Åü„Åæ„Åî',
            'ÈÖµÁ¥†', '„Çµ„Éó„É™', '„Éó„É≠„ÉÜ„Ç§„É≥', '„Éì„Çø„Éü„É≥', 'ÂÅ•Â∫∑È£üÂìÅ', 'Ê†ÑÈ§ä', 'ÈùíÊ±Å',
            '„Å´„Çì„Å´„Åè', '„Åó„Çá„ÅÜ„Åå', 'ÁîüÂßú', '‰∏ÉÂë≥', '„Çè„Åï„Å≥', 'ÊüöÂ≠ê', '„ÇÜ„Åö', '„Åã„Åº„Åô',
            # Cooking and food-related
            '„É¨„Ç∑„Éî', 'È£ü„ÅπÁâ©', 'È£ü‰∫ã', 'ÊúùÈ£ü', 'ÊòºÈ£ü', 'Â§ïÈ£ü', 'Â§úÈ£ü', 'ÈñìÈ£ü', '„Åä„ÇÑ„Å§',
            # Common food suffixes/prefixes
            'Âë≥', 'È¢®Âë≥', '„Éï„É¨„Éº„Éê„Éº', 'Áî£', 'ÁúåÁî£', 'ÂõΩÁî£', 'ÊúâÊ©ü', '„Ç™„Éº„Ç¨„Éã„ÉÉ„ÇØ'
        ]
        
        # 10% tax (standard rate) - general merchandise, electronics, etc.
        self.tax_10_keywords = [
            # Electronics and appliances
            'ÈõªÂ≠ê', 'ÈõªÊ∞ó', 'ÂÆ∂Èõª', '„Éë„ÇΩ„Ç≥„É≥', 'PC', '„Çπ„Éû„Éõ', '„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥', '„Ç´„É°„É©', '„ÉÜ„É¨„Éì',
            # Household items
            'ÂÆ∂ÂÖ∑', 'ÈõëË≤®', '„Ç§„É≥„ÉÜ„É™„Ç¢', '„Ç≠„ÉÉ„ÉÅ„É≥Áî®ÂìÅ', 'È£üÂô®', '„Ç∞„É©„Çπ', '„Ç´„ÉÉ„Éó', '„Éó„É¨„Éº„Éà',
            'ÊéÉÈô§', '„ÇØ„É™„Éº„Éä„Éº', 'Ê¥óÂâ§', '„Ç∑„É£„É≥„Éó„Éº', '„ÇΩ„Éº„Éó', 'Áü≥Èπ∏', '„Çø„Ç™„É´', '„Ç∑„Éº„ÉÑ',
            # Beauty and cosmetics
            'ÂåñÁ≤ßÂìÅ', '„Ç≥„Çπ„É°', 'ÁæéÂÆπ', '„Çπ„Ç≠„É≥„Ç±„Ç¢', 'È¶ôÊ∞¥', '„Éë„Éï„É•„Éº„É†', '„ÇØ„É™„Éº„É†', '„É≠„Éº„Ç∑„Éß„É≥',
            # Clothing and accessories
            'Êúç', 'Ë°£È°û', '„Éï„Ç°„ÉÉ„Ç∑„Éß„É≥', '„Éê„ÉÉ„Ç∞', 'Èù¥', '„Ç∑„É•„Éº„Ç∫', '„Ç¢„ÇØ„Çª„Çµ„É™„Éº', 'ÊôÇË®à',
            # Tools and equipment
            'Â∑•ÂÖ∑', 'ÈÅìÂÖ∑', 'Ê©üÊ¢∞', 'Âô®ÂÖ∑', 'Áî®ÂìÅ', 'Áî®ÂÖ∑', '„ÉÑ„Éº„É´', 'ÁÆí', '„Åª„ÅÜ„Åç', '„Éñ„É©„Ç∑',
            # Stationery and books
            'ÊñáÂÖ∑', 'ÊñáÊàøÂÖ∑', '„Éö„É≥', '„Éé„Éº„Éà', 'Êú¨', 'Êõ∏Á±ç', 'ÈõëË™å', '„Ç´„É¨„É≥„ÉÄ„Éº',
            # Toys and games
             '„Åä„ÇÇ„Å°„ÇÉ', '„Ç≤„Éº„É†', '„Éë„Ç∫„É´', '„Éï„Ç£„ÇÆ„É•„Ç¢',
            # Sports and outdoor
            '„Çπ„Éù„Éº„ÉÑ', 'ÈÅãÂãï', '„Ç¢„Ç¶„Éà„Éâ„Ç¢', '„Ç≠„É£„É≥„Éó', 'Èá£„Çä',
            # Alcoholic beverages (standard 10% tax in Japan)
            'ÈÖí', '„ÉØ„Ç§„É≥', '„Éì„Éº„É´', 'Êó•Êú¨ÈÖí', 'ÁÑºÈÖé', '„Ç¶„Ç§„Çπ„Ç≠„Éº', '„Éñ„É©„É≥„Éá„Éº', '„É™„Ç≠„É•„Éº„É´', 
            '„ÉÅ„É•„Éº„Éè„Ç§', '„Ç´„ÇØ„ÉÜ„É´', '„Çµ„ÉØ„Éº', '„Éè„Ç§„Éú„Éº„É´', '„Ç∑„É£„É≥„Éë„É≥', '„Çπ„Éë„Éº„ÇØ„É™„É≥„Ç∞', 
            '„É≠„Çº', 'ÁôΩ„ÉØ„Ç§„É≥', 'Ëµ§„ÉØ„Ç§„É≥', 'ÁîòÈÖí', '„Å©„Å∂„Çç„Åè', 'Ê¢ÖÈÖí', '„Ç¢„É´„Ç≥„Éº„É´', '„Ç®„Çø„Éé„Éº„É´',
            'ÈÖíÈÄ†', 'ÈÜ∏ÈÄ†', 'ËîµÂÖÉ', 'brewery', 'winery', 'distillery', 'sake', 'wine', 'beer', 'whisky',
            # General merchandise indicators
            '„Çª„ÉÉ„Éà', '„Ç≠„ÉÉ„Éà', '„Ç∞„ÉÉ„Ç∫', '„Ç¢„Ç§„ÉÜ„É†', 'ÂïÜÂìÅ', 'Ë£ΩÂìÅ', '„Éñ„É©„É≥„Éâ'
        ]
        
    def load_tax_data(self):
        """Load tax data from Japanese master files"""
        print("üìä Loading tax data from Japanese master files...")
        
        # Load „Çª„ÉÉ„ÉàÂïÜÂìÅ„Éû„Çπ„Çø
        set_products_file = self.data_dir / 'with-tax.csv'
        if set_products_file.exists():
            with open(set_products_file, 'r', encoding='shift-jis') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    product_code = row.get('ÂïÜÂìÅ„Ç≥„Éº„Éâ', '').strip()
                    set_code = row.get('„Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ', '').strip()
                    tax_rate = row.get('Ê∂àË≤ªÁ®éÁéáÔºà%Ôºâ', '').strip()
                    
                    if tax_rate:
                        tax_formatted = f"{tax_rate}%"
                        
                        # Map both ÂïÜÂìÅ„Ç≥„Éº„Éâ and „Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ to tax rate (case-insensitive)
                        if product_code:
                            self.tax_data[product_code.lower()] = tax_formatted
                        if set_code:
                            self.set_code_mapping[set_code.lower()] = tax_formatted
            
            total_mappings = len(self.tax_data) + len(self.set_code_mapping)
            print(f"  ‚úÖ Loaded from „Çª„ÉÉ„ÉàÂïÜÂìÅ„Éû„Çπ„Çø:")
            print(f"    ÂïÜÂìÅ„Ç≥„Éº„Éâ mappings: {len(self.tax_data)}")
            print(f"    „Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ mappings: {len(self.set_code_mapping)}")
            print(f"    Total mappings: {total_mappings}")
        
        # Load ÂïÜÂìÅ„Éû„Çπ„Çø (will override duplicates from set products)
        products_file = self.data_dir / 'ÂïÜÂìÅ„Éû„Çπ„Çø_20250912.csv'
        if products_file.exists():
            initial_count = len(self.tax_data)
            with open(products_file, 'r', encoding='shift-jis') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    code = row['ÂïÜÂìÅ„Ç≥„Éº„Éâ']
                    tax_rate = row['Ê∂àË≤ªÁ®éÁéáÔºà%Ôºâ']
                    if code and tax_rate:
                        # Format as percentage string for Shopify (case-insensitive)
                        self.tax_data[code.lower()] = f"{tax_rate}%"
            new_count = len(self.tax_data)
            print(f"  ‚úÖ Loaded {new_count - initial_count} additional products from ÂïÜÂìÅ„Éû„Çπ„Çø")
        
        # Combine all tax data for statistics
        all_tax_data = {}
        all_tax_data.update(self.tax_data)
        all_tax_data.update(self.set_code_mapping)
        
        print(f"üìã Total unique tax mappings available: {len(all_tax_data)}")
        
        # Show tax rate distribution
        tax_distribution = defaultdict(int)
        for tax_rate in all_tax_data.values():
            tax_distribution[tax_rate] += 1
        
        print("üìä Tax rate distribution:")
        for rate, count in sorted(tax_distribution.items()):
            print(f"  {rate}: {count} mappings")
    
    def get_tax_rate_for_handle(self, handle):
        """Get tax rate for handle, checking both ÂïÜÂìÅ„Ç≥„Éº„Éâ and „Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ mappings (case-insensitive)"""
        handle_lower = handle.lower()
        
        # First check ÂïÜÂìÅ„Ç≥„Éº„Éâ mapping
        if handle_lower in self.tax_data:
            return self.tax_data[handle_lower]
        
        # Then check „Çª„ÉÉ„ÉàÂïÜÂìÅ„Ç≥„Éº„Éâ mapping
        if handle_lower in self.set_code_mapping:
            return self.set_code_mapping[handle_lower]
        
        # Not found in either mapping
        return None
    
    def suggest_tax_rate(self, title, vendor="", product_type=""):
        """Suggest tax rate based on product title and other attributes"""
        if not title:
            return "10%"  # Default to standard rate
        
        # Convert to lowercase for matching
        title_lower = title.lower()
        vendor_lower = vendor.lower() if vendor else ""
        type_lower = product_type.lower() if product_type else ""
        
        # Combine all text for analysis
        combined_text = f"{title_lower} {vendor_lower} {type_lower}"
        
        # Count matches for each tax rate
        tax_8_matches = sum(1 for keyword in self.tax_8_keywords if keyword in combined_text)
        tax_10_matches = sum(1 for keyword in self.tax_10_keywords if keyword in combined_text)
        
        # Determine tax rate based on matches
        if tax_8_matches > tax_10_matches:
            return "8%"
        elif tax_10_matches > tax_8_matches:
            return "10%"
        else:
            # No clear match or tie - use heuristics
            
            # Food-related indicators (favor 8%)
            food_indicators = ['Âë≥', '„Éï„É¨„Éº„Éê„Éº', 'Áî£', 'ÁúåÁî£', 'ÂõΩÁî£', 'ml', 'g', 'kg', 'Ë¢ã', 'ÂÄãÂÖ•„Çä']
            if any(indicator in combined_text for indicator in food_indicators):
                return "8%"
            
            # Product/merchandise indicators (favor 10%)
            product_indicators = ['Áî®ÂìÅ', 'Áî®ÂÖ∑', '„Çª„ÉÉ„Éà', '„Ç≠„ÉÉ„Éà', 'cm', '„Çµ„Ç§„Ç∫', 'Ëâ≤']
            if any(indicator in combined_text for indicator in product_indicators):
                return "10%"
            
            # Default to standard rate
            return "10%"
    
    def backup_file(self, file_path):
        """Create backup of original file"""
        if not self.backup:
            return
            
        backup_path = file_path.with_suffix(f'.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
        shutil.copy2(file_path, backup_path)
        print(f"  üíæ Backup created: {backup_path.name}")
    
    def process_export_file(self, file_path):
        """Process a single export CSV file"""
        print(f"\nüîÑ Processing {file_path.name}...")
        
        if not file_path.exists():
            error_msg = f"File not found: {file_path}"
            print(f"  ‚ùå {error_msg}")
            self.results['errors'].append(error_msg)
            return
        
        # Create backup if requested
        if self.backup:
            self.backup_file(file_path)
        
        # Read the file
        updated_rows = []
        file_stats = {
            'total': 0,
            'matched': 0,
            'unmatched': 0,
            'updated': 0,
            'skipped_variants': 0
        }
        
        # Track processed handles to identify main product vs variants
        processed_handles = set()
        
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            fieldnames = reader.fieldnames
            
            # Verify tax column exists
            tax_column = 'Ê∂àË≤ªÁ®éÁéá (product.metafields.custom.tax)'
            if tax_column not in fieldnames:
                error_msg = f"Tax column not found in {file_path.name}: {tax_column}"
                print(f"  ‚ùå {error_msg}")
                self.results['errors'].append(error_msg)
                return
            
            for row in reader:
                file_stats['total'] += 1
                handle = row['Handle']
                current_tax = row[tax_column].strip()
                
                # Check if this is the main product row (first occurrence of handle)
                is_main_product = handle not in processed_handles
                
                if is_main_product:
                    processed_handles.add(handle)
                    
                    # Check if we have tax data for this product (both mappings)
                    new_tax = self.get_tax_rate_for_handle(handle)
                    if new_tax:
                        file_stats['matched'] += 1
                        
                        # Track matched product for JSON export
                        title = row.get('Title', '').strip()
                        self.matched_products.append({
                            'handle': handle,
                            'tax_rate': new_tax,
                            'title': title,
                            'source_file': file_path.name
                        })
                        
                        # Update only if different
                        if current_tax != new_tax:
                            row[tax_column] = new_tax
                            file_stats['updated'] += 1
                        
                    else:
                        file_stats['unmatched'] += 1
                        # Track unmatched product details with intelligent tax suggestion
                        # Only for main product rows with actual titles
                        title = row.get('Title', '').strip()
                        vendor = row.get('Vendor', '').strip()
                        product_type = row.get('Type', '').strip()
                        
                        # Only add to unmatched list if it has meaningful content
                        if title or vendor or product_type:
                            suggested_tax = self.suggest_tax_rate(title, vendor, product_type)
                            
                            self.unmatched_products.append({
                                'handle': handle,
                                'title': title,
                                'vendor': vendor,
                                'type': product_type,
                                'source_file': file_path.name,
                                'current_tax': current_tax,
                                'suggested_tax_rate': suggested_tax
                            })
                else:
                    # This is a variant row - skip tax processing but copy any tax from main product
                    file_stats['skipped_variants'] += 1
                    # Variants inherit tax from main product if we have it
                    if not current_tax:
                        new_tax = self.get_tax_rate_for_handle(handle)
                        if new_tax:
                            row[tax_column] = new_tax
                
                updated_rows.append(row)
        
        # Write updated file (unless dry run)
        if not self.dry_run and file_stats['updated'] > 0:
            with open(file_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(updated_rows)
            print(f"  ‚úÖ File updated successfully")
        elif self.dry_run:
            print(f"  üîç DRY RUN: Would update {file_stats['updated']} products")
        else:
            print(f"  ‚ÑπÔ∏è  No updates needed")
        
        # Print file statistics
        main_products = file_stats['matched'] + file_stats['unmatched']
        print(f"  üìä Statistics:")
        print(f"    Total rows: {file_stats['total']}")
        print(f"    Main products: {main_products}")
        print(f"    Variant rows (skipped): {file_stats['skipped_variants']}")
        print(f"    Matched with tax data: {file_stats['matched']} ({file_stats['matched']/main_products*100:.1f}% of main products)")
        print(f"    Products updated: {file_stats['updated']}")
        print(f"    Unmatched main products: {file_stats['unmatched']}")
        
        # Update overall results
        self.results['files_processed'] += 1
        self.results['products_updated'] += file_stats['updated']
        self.results['products_matched'] += file_stats['matched']
        self.results['products_unmatched'] += file_stats['unmatched']
    
    def process_all_exports(self, single_file=None):
        """Process all export files or a single specified file"""
        if single_file:
            # Process single file
            file_path = self.data_dir / single_file
            self.process_export_file(file_path)
        else:
            # Process all export files
            export_files = sorted(self.data_dir.glob('products_export_*.csv'))
            if not export_files:
                print("‚ùå No export files found matching pattern: products_export_*.csv")
                return
            
            print(f"üìÅ Found {len(export_files)} export files to process")
            for file_path in export_files:
                self.process_export_file(file_path)
    
    def generate_unmatched_csv_report(self):
        """Generate CSV report of unmatched products"""
        if not self.unmatched_products:
            print("‚ÑπÔ∏è  No unmatched products to report")
            return
        
        # Create reports directory if it doesn't exist
        reports_dir = Path('api-operations/reports')
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate CSV report
        csv_file = reports_dir / 'unmatched_products_report.csv'
        
        fieldnames = ['handle', 'title', 'vendor', 'type', 'source_file', 'current_tax', 'suggested_tax_rate']
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.unmatched_products)
        
        print(f"üìÑ Unmatched products CSV report saved: {csv_file}")
        print(f"   Total unmatched products: {len(self.unmatched_products)}")
        
        # Show breakdown by source file
        file_counts = defaultdict(int)
        for product in self.unmatched_products:
            file_counts[product['source_file']] += 1
        
        print("üìä Unmatched products by source file:")
        for file_name, count in sorted(file_counts.items()):
            print(f"  {file_name}: {count} products")
        
        # Show tax suggestion distribution
        suggestion_counts = defaultdict(int)
        for product in self.unmatched_products:
            suggestion_counts[product['suggested_tax_rate']] += 1
        
        print("üìä Tax rate suggestions for unmatched products:")
        for rate, count in sorted(suggestion_counts.items()):
            print(f"  {rate}: {count} products")
    
    def generate_tax_update_json(self):
        """Generate JSON file for GraphQL script with handle‚Üítax_rate mappings"""
        if not self.matched_products and not self.unmatched_products:
            print("‚ÑπÔ∏è  No products to export to JSON")
            return
        
        # Create reports directory if it doesn't exist
        reports_dir = Path('api-operations/shared')
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        # Prepare data for JSON export
        all_products = []
        
        # Add matched products (from master files)
        for product in self.matched_products:
            all_products.append({
                'handle': product['handle'],
                'tax_rate': product['tax_rate'],
                'title': product['title'],
                'source': 'master_file'
            })
        
        # Add unmatched products with intelligent suggestions
        for product in self.unmatched_products:
            all_products.append({
                'handle': product['handle'],
                'tax_rate': product['suggested_tax_rate'],
                'title': product['title'],
                'source': 'intelligent_suggestion'
            })
        
        json_data = {
            'timestamp': datetime.now().isoformat(),
            'description': 'Tax rate mappings for Shopify GraphQL updates (matched + suggested)',
            'total_products': len(all_products),
            'matched_count': len(self.matched_products),
            'suggested_count': len(self.unmatched_products),
            'data': all_products
        }
        
        # Save JSON file
        json_file = reports_dir / 'tax_data_to_update.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ Tax update JSON saved: {json_file}")
        print(f"   Total products for Shopify update: {len(all_products)}")
        print(f"   From master files: {len(self.matched_products)}")
        print(f"   From intelligent suggestions: {len(self.unmatched_products)}")
        
        # Show tax rate distribution for all updates
        update_distribution = defaultdict(int)
        source_distribution = defaultdict(int)
        
        for product in all_products:
            update_distribution[product['tax_rate']] += 1
            source_distribution[product['source']] += 1
        
        print("üìä Tax rates to be updated in Shopify:")
        for rate, count in sorted(update_distribution.items()):
            print(f"  {rate}: {count} products")
        
        print("üìä Sources breakdown:")
        for source, count in sorted(source_distribution.items()):
            print(f"  {source}: {count} products")

    def generate_report(self):
        """Generate summary report"""
        print(f"\nüìã TAX APPLICATION SUMMARY")
        print(f"{'='*50}")
        print(f"Files processed: {self.results['files_processed']}")
        print(f"Products updated: {self.results['products_updated']}")
        print(f"Products matched: {self.results['products_matched']}")
        print(f"Products unmatched: {self.results['products_unmatched']}")
        
        if self.results['products_matched'] + self.results['products_unmatched'] > 0:
            total = self.results['products_matched'] + self.results['products_unmatched']
            match_rate = self.results['products_matched'] / total * 100
            print(f"Match rate: {match_rate:.1f}%")
        
        if self.results['errors']:
            print(f"\n‚ùå Errors encountered:")
            for error in self.results['errors']:
                print(f"  - {error}")
        
        # Save detailed report
        report_file = Path('api-operations/reports/tax_application_report.json')
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Calculate tax distribution first
        tax_distribution = defaultdict(int)
        for tax_rate in self.tax_data.values():
            tax_distribution[tax_rate] += 1
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'settings': {
                'dry_run': self.dry_run,
                'backup': self.backup
            },
            'results': self.results,
            'tax_data_stats': {
                'total_available': len(self.tax_data),
                'distribution': dict(tax_distribution)
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Detailed report saved: {report_file}")
        
        # Generate CSV report for unmatched products
        self.generate_unmatched_csv_report()
        
        # Generate JSON file for GraphQL updates
        self.generate_tax_update_json()

def main():
    parser = argparse.ArgumentParser(description='Apply tax data to Shopify export CSVs')
    parser.add_argument('--dry-run', action='store_true', 
                       help='Preview changes without modifying files')
    parser.add_argument('--backup', action='store_true',
                       help='Create backup files before modification')
    parser.add_argument('--file', type=str,
                       help='Process single file instead of all exports')
    parser.add_argument('--data-dir', type=str, default='api-operations/data',
                       help='Directory containing data files (relative to current working directory)')
    
    args = parser.parse_args()
    
    print("üè∑Ô∏è  TAX DATA APPLICATOR")
    print("="*50)
    
    if args.dry_run:
        print("üîç DRY RUN MODE: No files will be modified")
    if args.backup:
        print("üíæ BACKUP MODE: Original files will be backed up")
    
    try:
        applicator = TaxDataApplicator(
            data_dir=args.data_dir,
            backup=args.backup,
            dry_run=args.dry_run
        )
        
        # Load tax data from master files
        applicator.load_tax_data()
        
        if len(applicator.tax_data) == 0:
            print("‚ùå No tax data loaded. Please check master files exist and are readable.")
            return
        
        # Process export files
        applicator.process_all_exports(single_file=args.file)
        
        # Generate summary report
        applicator.generate_report()
        
        print("\n‚úÖ Tax application completed successfully!")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        raise

if __name__ == '__main__':
    main()